{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b14135",
   "metadata": {},
   "source": [
    "1-imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262445ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bfc2d",
   "metadata": {},
   "source": [
    "2-Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b160a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial Data (Ratings Table) ---\n",
      "          userId  movieId  rating            timestamp\n",
      "0              1        2     3.5  2005-04-02 23:53:47\n",
      "1              1       29     3.5  2005-04-02 23:31:16\n",
      "2              1       32     3.5  2005-04-02 23:33:39\n",
      "3              1       47     3.5  2005-04-02 23:32:07\n",
      "4              1       50     3.5  2005-04-02 23:29:40\n",
      "...          ...      ...     ...                  ...\n",
      "20000258  138493    68954     4.5  2009-11-13 15:42:00\n",
      "20000259  138493    69526     4.5  2009-12-03 18:31:48\n",
      "20000260  138493    69644     3.0  2009-12-07 18:10:57\n",
      "20000261  138493    70286     5.0  2009-11-13 15:42:24\n",
      "20000262  138493    71619     2.5  2009-10-17 20:25:36\n",
      "\n",
      "[20000263 rows x 4 columns]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Define the dimensionality (size) of the embedding vector.\n",
    "# We use 3 for simplicity in the example, but 100 or 256 is common in real systems.\n",
    "EMBEDDING_DIMENSION = 50\n",
    "\n",
    "# --- 2. SAMPLE DATA (REPLACING 'ratings.csv') ---\n",
    "# In a real scenario, you would use: df = pd.read_csv('ratings.csv')\n",
    "print(\"--- Initial Data (Ratings Table) ---\")\n",
    "df = pd.read_csv('./data/rating.csv')\n",
    "print(df)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f092b7",
   "metadata": {},
   "source": [
    "3-Create Id-To-Index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24121d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping User IDs to Array Index:\n",
      "1\n",
      "Mapping Movie IDs to Array Index:\n",
      "0\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. CREATE ID-TO-INDEX MAPPINGS ---\n",
    "# We need to map the unique, non-sequential IDs (e.g., 5001, 5002) to \n",
    "# sequential array indices (0, 1, 2...) for efficient lookup.\n",
    "\n",
    "unique_users = df['userId'].unique()\n",
    "unique_movies = df['movieId'].unique()\n",
    "\n",
    "# Maps original ID -> Array Index\n",
    "# --- Explicit Loop for Users ---\n",
    "user_to_idx = {}\n",
    "# enumerate returns (index, value). Example: (0, 101), (1, 102)\n",
    "for index, user_id in enumerate(unique_users):\n",
    "    # Store: { Original ID : Array Index }\n",
    "    user_to_idx[user_id] = index \n",
    "\n",
    "# --- Explicit Loop for Movies ---\n",
    "movie_to_idx = {}\n",
    "for index, movie_id in enumerate(unique_movies):\n",
    "    movie_to_idx[movie_id] = index\n",
    "    \n",
    "print(\"Mapping User IDs to Array Index:\")\n",
    "print(user_to_idx[2])\n",
    "print(\"Mapping Movie IDs to Array Index:\")\n",
    "print(movie_to_idx[2])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b498f6d",
   "metadata": {},
   "source": [
    "4-Initialize random embedding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3020724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Embedding Matrix (W_user) Shape: (138493, 50)\n",
      "Movie Embedding Matrix (W_movie) Shape: (26744, 50)\n",
      "\n",
      "Example of User of ID = 101 (vector format):\n",
      "[ 0.43564307  0.97449836 -0.37775465 -0.95418875 -0.23995074  0.48664576\n",
      "  0.45864161 -0.93614468 -0.93332675 -0.22691458  0.69949299 -0.464135\n",
      "  0.66474404 -0.96346142  0.73242426 -0.46800001  0.98787577  0.8561139\n",
      " -0.6231519  -0.65145213  0.10275017  0.18954588 -0.06239443  0.27914489\n",
      "  0.52363129 -0.12688866 -0.07940699 -0.03169153 -0.93526102  0.37147882\n",
      "  0.67400882  0.31008283 -0.03693043  0.24533074 -0.66290096 -0.46751943\n",
      " -0.81646319 -0.16601179 -0.80262719  0.82980696  0.14026866 -0.62550372\n",
      "  0.62211017 -0.72869238 -0.89877266 -0.75431576 -0.71831733  0.34819833\n",
      "  0.73009655 -0.16366827]\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4. INITIALIZE RANDOM EMBEDDING MATRICES (W) ---\n",
    "# Each row in these matrices is the random vector for one unique entity.\n",
    "\n",
    "num_users = len(unique_users)\n",
    "num_movies = len(unique_movies)\n",
    "\n",
    "# Create a matrix of size (Number of Unique Users) x (Dimension)\n",
    "# The values are random floats between -1 and 1.\n",
    "users_embed = np.random.uniform(\n",
    "    low=-1.0, high=1.0, \n",
    "    size=(num_users, EMBEDDING_DIMENSION)\n",
    ")\n",
    "\n",
    "# Create a matrix of size (Number of Unique Movies) x (Dimension)\n",
    "movies_embed = np.random.uniform(\n",
    "    low=-1.0, high=1.0, \n",
    "    size=(num_movies, EMBEDDING_DIMENSION)\n",
    ")\n",
    "\n",
    "print(f\"User Embedding Matrix (W_user) Shape: {users_embed.shape}\")\n",
    "print(f\"Movie Embedding Matrix (W_movie) Shape: {movies_embed.shape}\")\n",
    "print(\"\\nExample of User of ID = 101 (vector format):\")\n",
    "print(users_embed[user_to_idx[101]])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde3533",
   "metadata": {},
   "source": [
    "5-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb500424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building X and Y by Iterating and Concatenating...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding X and Y by Iterating and Concatenating...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Loop through every single rating event (row)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 1. Look up the index of the current userId and movieId\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mu_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_to_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muserId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mm_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmovie_to_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:1559\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1557\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m-> 1559\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[0;32m   1561\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\construction.py:604\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    602\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 604\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m object_index \u001b[38;5;129;01mand\u001b[39;00m using_string_dtype() \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr):\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[0;32m    607\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1198\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[1;34m(value, convert_to_nullable_dtype)\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[1;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_non_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_to_nullable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM8[ns]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpandas/_libs/lib.pyx:2560\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\numpy\\_core\\numeric.py:384\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, device, like)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _full_with_like(\n\u001b[0;32m    380\u001b[0m         like, shape, fill_value, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m    381\u001b[0m     )\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 384\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    386\u001b[0m a \u001b[38;5;241m=\u001b[39m empty(shape, dtype, order, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. BUILD FINAL FEATURE MATRIX (X) AND TARGET (Y) ---\n",
    "# We iterate through every rating and look up the 100-dimensional vector \n",
    "# for both the user and the movie, then concatenate them.\n",
    "\n",
    "# Lists to hold our final data\n",
    "X_features = []\n",
    "Y_ratings = []\n",
    "\n",
    "print(\"Building X and Y by Iterating and Concatenating...\")\n",
    "\n",
    "# Loop through every single rating event (row)\n",
    "for index, row in df.iterrows():\n",
    "    # 1. Look up the index of the current userId and movieId\n",
    "    u_idx = user_to_idx[row['userId']]\n",
    "    m_idx = movie_to_idx[row['movieId']]\n",
    "\n",
    "    # 2. Retrieve the n-dimensional random vectors (the embeddings)\n",
    "    user_vector = users_embed[u_idx]\n",
    "    movie_vector = movies_embed[m_idx]\n",
    "    # print(index)\n",
    "    # 3. Concatenate (join) the two vectors to create a single feature vector (2*3=6 dimensions)\n",
    "    # This is the feature vector (x_k) for this specific rating event\n",
    "    combined_feature_vector = np.concatenate([user_vector, movie_vector])\n",
    "\n",
    "    # 4. Store the results\n",
    "    X_features.append(combined_feature_vector)\n",
    "    Y_ratings.append(row['rating'])\n",
    "    \n",
    "    # Optional: Print first two feature vectors to show the concatenation\n",
    "    # if index < 2:\n",
    "    #     print(f\"\\nRating {index}: User {row['userId']} rated Movie {row['movieId']} with {row['rating']}\")\n",
    "    #     print(f\"  User Vector: {user_vector}\")\n",
    "    #     print(f\"  Movie Vector: {movie_vector}\")\n",
    "    #     print(f\"  Combined X: {combined_feature_vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69646591",
   "metadata": {},
   "source": [
    "6-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(X_features)\n",
    "Y = np.array(Y_ratings)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(f\"FINAL FEATURE MATRIX X (Input for Model) Shape: {X.shape}\")\n",
    "print(f\"FINAL TARGET VECTOR Y (Ratings) Shape: {Y.shape}\")\n",
    "print(\"\\nFirst row of X (6-dimensional feature vector):\")\n",
    "print(X[0])\n",
    "print(\"\\nFirst value of Y (the rating):\")\n",
    "print(Y[0])\n",
    "\n",
    "# X and Y are now ready to be split into training/testing sets and fed into \n",
    "# a model like LinearRegression. The model will learn to optimize the \n",
    "# values in the initial 'users_embed' and 'movies_embed' matrices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
